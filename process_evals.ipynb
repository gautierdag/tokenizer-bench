{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import logging\n",
    "\n",
    "# Set the logging level to WARNING to suppress DEBUG messages\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# Alternatively, you can set the level specifically for urllib3\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "\n",
    "from utils import renyi_efficiency\n",
    "\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "core_models = {\n",
    "    \"gpt2\": \"gpt2\",\n",
    "    \"mpt\": \"mosaicml/mpt-7b-instruct\",\n",
    "    \"bloom\": \"bigscience/bloom-7b1\",\n",
    "    \"gpt-neox\": \"EleutherAI/gpt-neox-20b\",\n",
    "    \"falcon\": \"tiiuae/falcon-40b\",\n",
    "    \"pythia\": \"EleutherAI/pythia-12b\",\n",
    "    \"codet5\": \"Salesforce/codet5-small\",\n",
    "    \"incoder\": \"facebook/incoder-1B\",\n",
    "    \"starcoder\": \"bigcode/starcoder\",\n",
    "    \"replit\": \"replit/replit-code-v1_5-3b\",\n",
    "    \"codegen\": \"Salesforce/codegen-350M-mono\",\n",
    "    \"byt5\": \"google/byt5-small\",\n",
    "    \"deepseek-coder\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"Yi-6B\": \"01-ai/Yi-6B\",\n",
    "    \"mistral\": \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"santacoder\": \"bigcode/santacoder\",\n",
    "    \"llama\": \"meta-llama/Llama-2-7b\",\n",
    "}\n",
    "\n",
    "\n",
    "sizes = {\n",
    "    \"gpt4\": 100_256,\n",
    "    \"gpt-neox\": 50_257,\n",
    "}\n",
    "\n",
    "\n",
    "def load_tokenizer(model_path: str):\n",
    "    if model_path in core_models:\n",
    "        pretrained_name = core_models[model_path]\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            pretrained_name, trust_remote_code=True\n",
    "        )\n",
    "    elif os.path.exists(f\"tokenizers/{model_path}.json\"):\n",
    "        tokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_file=f\"tokenizers/{model_path}.json\"\n",
    "        )\n",
    "    elif os.path.exists(f\"tokenizers/{model_path}.model\"):\n",
    "        tokenizer = SentencePieceProcessor(model_file=f\"tokenizers/{model_path}.model\")\n",
    "    else:\n",
    "        return 0\n",
    "    return len(tokenizer)\n",
    "\n",
    "\n",
    "def column_explosion(col: str):\n",
    "    def explode_dict_to_series(in_dict):\n",
    "        keys = [\n",
    "            \"Compression\",\n",
    "            \"Renyi\",\n",
    "            \"Token Count\",\n",
    "            \"Bytes per Token\",\n",
    "            \"Chars per Token\",\n",
    "            \"Tokens per Byte\",\n",
    "            \"Tokens per Char\",\n",
    "            \"Gini\",\n",
    "        ]\n",
    "        # keys = [\"Compression\"]\n",
    "        out_dict = {f\"{col} {key}\": in_dict[key] for key in keys}\n",
    "        return pd.Series(out_dict)\n",
    "\n",
    "    return explode_dict_to_series\n",
    "\n",
    "\n",
    "def name_to_params(name: str) -> dict:\n",
    "    if name in sizes:\n",
    "        return {\"vs\": sizes[name]}\n",
    "    params = {\"rsc\": 0, \"u64\": 0, \"sp\": False}\n",
    "    splits = name.split(\"_\")\n",
    "\n",
    "    for i, split in enumerate(splits):\n",
    "        if split == \"rsc\":\n",
    "            params[\"rsc\"] = 1\n",
    "        if split == \"u64\":\n",
    "            params[\"u64\"] = 1\n",
    "        if split == \"sp\":\n",
    "            params[\"sp\"] = True\n",
    "        if split == \"cp\":\n",
    "            params[\"cp\"] = float(splits[i + 1])\n",
    "        if split == \"mp\":\n",
    "            params[\"mp\"] = float(splits[i + 1])\n",
    "        if split == \"nc\":\n",
    "            # number of characters in Billions\n",
    "            params[\"nc\"] = int(int(splits[i + 1]) / 1_000_000_000)\n",
    "        if split == \"msl\":\n",
    "            params[\"msl\"] = splits[i + 1]\n",
    "        if split == \"mt\":\n",
    "            params[\"mt\"] = splits[i + 1]\n",
    "        if split == \"nrn\":\n",
    "            params[\"nrn\"] = splits[i + 1]\n",
    "        if split == \"ncf\":\n",
    "            params[\"ncf\"] = int(splits[i + 1])\n",
    "        if split == \"vs\":\n",
    "            params[\"vs\"] = int(splits[i + 1])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = glob.glob(\"data/*/test/*.jsonl\")\n",
    "dataset_stats = {}\n",
    "for dataset in datasets:\n",
    "    dataset_name = dataset.split(\"/\")[-1].replace(\".jsonl\", \"\")\n",
    "    if dataset_name in dataset_stats:\n",
    "        continue\n",
    "    dataset_stats[dataset_name] = {}\n",
    "    data = []\n",
    "    with open(dataset, \"r\") as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    dataset_stats[dataset_name][\"total_chars\"] = sum([d[\"char_size\"] for d in data])\n",
    "    dataset_stats[dataset_name][\"total_bytes\"] = sum([d[\"byte_size\"] for d in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_files = glob.glob(\"evals/*.json\")\n",
    "evals = {}\n",
    "for eval_file in tqdm(eval_files):\n",
    "    eval_name = eval_file.split(\"/\")[-1].replace(\".eval.json\", \"\")\n",
    "    if eval_name in evals:\n",
    "        continue\n",
    "    with open(eval_file, \"r\") as f:\n",
    "        evals[eval_name] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate eval statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# calculate compression\n",
    "for eval_name in tqdm(evals):\n",
    "    norm = \"llama\"\n",
    "    assert norm in evals\n",
    "    for dataset in evals[eval_name]:\n",
    "        evals[eval_name][dataset][\"Renyi\"] = renyi_efficiency(\n",
    "            Counter(evals[eval_name][dataset][\"vocab_counter\"]), power=2.5\n",
    "        )\n",
    "        evals[eval_name][dataset][\"Token Count\"] = sum(\n",
    "            evals[eval_name][dataset][\"lengths\"]\n",
    "        )\n",
    "        evals[eval_name][dataset][\"Bytes per Token\"] = (\n",
    "            dataset_stats[dataset][\"total_bytes\"]\n",
    "            / evals[eval_name][dataset][\"Token Count\"]\n",
    "        )\n",
    "        evals[eval_name][dataset][\"Chars per Token\"] = (\n",
    "            dataset_stats[dataset][\"total_chars\"]\n",
    "            / evals[eval_name][dataset][\"Token Count\"]\n",
    "        )\n",
    "        evals[eval_name][dataset][\"Tokens per Char\"] = (\n",
    "            evals[eval_name][dataset][\"Token Count\"]\n",
    "            / dataset_stats[dataset][\"total_chars\"]\n",
    "        )\n",
    "        evals[eval_name][dataset][\"Tokens per Byte\"] = (\n",
    "            evals[eval_name][dataset][\"Token Count\"]\n",
    "            / dataset_stats[dataset][\"total_bytes\"]\n",
    "        )\n",
    "        evals[eval_name][dataset][\"Compression\"] = evals[eval_name][dataset][\n",
    "            \"Token Count\"\n",
    "        ] / sum(evals[norm][dataset][\"lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"to evals df\")\n",
    "df = pd.DataFrame.from_dict(evals, orient=\"index\")\n",
    "\n",
    "for col in tqdm(df.columns):\n",
    "    df = df.join(df[col].apply(column_explosion(col)))\n",
    "    df.drop(columns=[col], inplace=True)\n",
    "\n",
    "df[\"Tokenizer\"] = df.index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.join(df[\"Tokenizer\"].apply(name_to_params).apply(pd.Series))\n",
    "df[\"Vocabulary Size\"] = df.Tokenizer.progress_apply(load_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values\n",
    "df.loc[df[\"Vocabulary Size\"] == 0, \"Vocabulary Size\"] = df.loc[\n",
    "    df[\"Vocabulary Size\"] == 0, \"vs\"\n",
    "]\n",
    "df[\"Vocabulary Size\"] = df[\"Vocabulary Size\"].fillna(df[\"vs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "code_datasets = [\n",
    "    p.split(\"/\")[-1].replace(\".jsonl\", \"\") for p in glob.glob(\"data/code/test/*\")\n",
    "]\n",
    "\n",
    "\", \".join(sorted(code_datasets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average over code/english/multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_datasets = [\n",
    "    p.split(\"/\")[-1].replace(\".jsonl\", \"\") for p in glob.glob(\"data/code/test/*\")\n",
    "]\n",
    "english_datasets = [\n",
    "    p.split(\"/\")[-1].replace(\".jsonl\", \"\") for p in glob.glob(\"data/english/test/*\")\n",
    "]\n",
    "multilingual_datasets = [\n",
    "    p.split(\"/\")[-1].replace(\".jsonl\", \"\")\n",
    "    for p in glob.glob(\"data/multilingual/test/*\")\n",
    "]\n",
    "\n",
    "compression_metrics = [\n",
    "    \"Compression\",\n",
    "    \"Bytes per Token\",\n",
    "    \"Chars per Token\",\n",
    "    \"Tokens per Byte\",\n",
    "    \"Tokens per Char\",\n",
    "    \"Renyi\",\n",
    "    \"Token Count\",\n",
    "    \"Gini\"\n",
    "]\n",
    "\n",
    "out_cols = []\n",
    "\n",
    "for compression_metric in tqdm(compression_metrics):\n",
    "    code_compression_metric_cols = [\n",
    "        f\"{dataset} {compression_metric}\" for dataset in code_datasets\n",
    "    ]\n",
    "    english_compression_metric_cols = [\n",
    "        f\"{dataset} {compression_metric}\" for dataset in english_datasets\n",
    "    ]\n",
    "    multilingual_compression_metric_cols = [\n",
    "        f\"{dataset} {compression_metric}\" for dataset in multilingual_datasets\n",
    "    ]\n",
    "\n",
    "    df[\"Average Code \" + compression_metric] = df[code_compression_metric_cols].mean(\n",
    "        axis=1\n",
    "    )\n",
    "    df[\"Average English \" + compression_metric] = df[\n",
    "        english_compression_metric_cols\n",
    "    ].mean(axis=1)\n",
    "    df[\"Average Multilingual \" + compression_metric] = df[\n",
    "        multilingual_compression_metric_cols\n",
    "    ].mean(axis=1)\n",
    "\n",
    "    average_cols = [\n",
    "        f\"Average Code {compression_metric}\",\n",
    "        f\"Average English {compression_metric}\",\n",
    "        f\"Average Multilingual {compression_metric}\",\n",
    "    ]\n",
    "    df[\"Average \" + compression_metric] = df[average_cols].mean(axis=1)\n",
    "\n",
    "    out_cols += [\"Average \" + compression_metric] + average_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cols = [\"Tokenizer\", \"Vocabulary Size\"] + out_cols\n",
    "\n",
    "\n",
    "second_cols = sorted(\n",
    "    list(\n",
    "        set(df.columns)\n",
    "        - set(first_cols)\n",
    "        - set([\"rsc\", \"u64\", \"sp\", \"cp\", \"msl\", \"mt\", \"mp\", \"nrn\", \"nc\", \"vs\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df[first_cols + second_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"eval_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokenizers-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
